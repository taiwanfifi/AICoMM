# Review 白話解讀

**對應文件**: `REVIEW_2026-02-12.md`
**用途**: 用工程直覺說明 reviewer 到底在講什麼、我們的論文哪裡站得住、哪裡站不住

---

## 一句話總結

Scout 的點子是真的新，但兩篇論文的「標題數字」在樣本放大後都撐不住。

---

## 先講好消息：什麼東西是穩的

### 1. Scout 的核心概念沒人做過

搜了 53 篇相關論文，沒有任何一篇做「用小模型的 attention 來幫大模型選 KV-cache 位置」這件事。

現有的做法都是：
- 壓縮 KV 資料再傳（CacheGen，壓 3.5 倍）
- 小模型猜 token 讓大模型驗（EAGLE、Medusa）
- 把模型切層分到不同裝置（EdgeShard、Splitwise）

我們做的是：小模型跑完 prefill，只傳「哪些位置重要」的索引（336 bytes），大模型自己重新 prefill 再套 mask。

這個概念在文獻裡是空白的。

### 2. 位置重疊率 82-83% 是真的

n=50 的時候量到 83.4%，n=200 的時候量到 83.7%。非常穩定。

白話講：7B 模型覺得重要的 token 位置，14B 模型也覺得有 83% 是重要的。這代表同家族模型的 attention 分布高度相似，Scout 的基礎假設成立。

### 3. 28,800 倍壓縮是真的

算法：
- 7B 模型的 KV-cache（1024 tokens）= 9.7 MB
- Scout 傳的位置索引 = 336 bytes
- 9.7 MB / 336 B = 28,869 倍

這個數字是物理量，不會因為樣本數改變。

### 4. INT8 量化無損、INT4 會炸

| 量化方式 | Qwen-7B 表現 | 白話翻譯 |
|---------|------------|---------|
| BF16（原始）| 100% | 基準線 |
| INT8 | 99.4% | 幾乎沒差 |
| INT4 | 68.7% | 炸了，品質掉三成 |
| Mixed-INT4 | 93.6% | 保護敏感層後恢復大部分 |

Perplexity 也驗證了：INT4 的 perplexity 從 8.6 暴漲到 80.3（正常值 < 10）。

### 5. Adaptive protocol 打贏 static

Scout 模式：100% 達標率（所有 request 都在 deadline 內完成）
Static INT8：只有 59% 達標率

---

## 再講壞消息：什麼東西站不住

### 問題 1（致命）：Q2C 其實跟 SnapKV 一樣好

Paper A 摘要寫：「Q2C 在 25% retention 比 SnapKV 好 29-47%」

這個數字來自 n=50 的實驗。當我們把樣本放大到 n=200：

| Retention | Q2C F1 | SnapKV F1 | p-value | 白話翻譯 |
|-----------|--------|-----------|---------|---------|
| 75% | 0.608 | 0.608 | 0.319 | 一模一樣 |
| 50% | 0.541 | 0.544 | 0.319 | 一模一樣 |
| 25% | 0.368 | 0.366 | 0.751 | 一模一樣 |

p > 0.3 代表什麼？代表「Q2C 和 SnapKV 的差異，跟隨機波動一樣大」。29-47% 的優勢完全是 n=50 的抽樣誤差。

**工程直覺**：你擲硬幣 50 次可能出現 60% 正面，但擲 200 次就會回到 50%。Q2C vs SnapKV 就是這個情況。

### 問題 2（致命）：7B 幫助 14B 的效果縮水

Paper B 摘要寫：「7B scout 讓 14B 品質提升 10.2%（p=0.018）」

n=50 的數據：scout F1 = 0.714，cloud own = 0.648，差距 +0.066
n=200 的數據：

| Retention | 差距 | p-value | Bonferroni 後 | 白話翻譯 |
|-----------|------|---------|-------------|---------|
| 75% | -0.004 | 0.883 | 不顯著 | 沒差 |
| 50% | +0.047 | 0.110 | 不顯著 | 有趨勢但不確定 |
| 25% | +0.059 | 0.039 | 不顯著 | 有趨勢但多重比較修正後不算 |

10.2% 的改善縮水成 4.7%，而且統計上不顯著。方向是對的（scout 確實傾向幫助大模型），但效果太小，n=200 不夠證明。

**工程直覺**：就像量測兩條生產線的良率，一條 49.9%、一條 54.6%。差距看起來有，但如果每條線只量了 200 個產品，你沒辦法確定這個差距是真的還是運氣。

### 問題 3（嚴重）：混合精度量化被搶先了

KVTuner（ICML 2025）已經發表了「根據每層敏感度分配不同量化精度」這個想法。跟我們 Paper A 的 Contribution 2 幾乎一樣。

不能再把這個當成新貢獻。只能降級成「支持性分析」。

### 問題 4（嚴重）：Q2C 公式兩篇論文不一致

- Paper A：Q2C = 最後一層的 attention score
- Paper B：Q2C = 所有層的平均 attention score
- 程式碼：用最後一層

Ablation 實驗證明兩種定義的結果幾乎一樣（Pearson r > 0.99），所以不影響結論，但數學定義不能自相矛盾。合併成 JSAC 的時候必須統一。

### 問題 5（中等）：實驗的 context 太短

論文開頭用「1024 token 的 KV-cache 超過 200 MB」來 motivate 問題，但實際實驗用的 SQuAD v2 context 平均只有 170 tokens。

雖然後來有跑 1K-2K token 的 overlap 實驗，但只量了「重疊率」，沒量「任務品質」。嚴格來說，我們沒有在 1024 token 下驗證 scout 真的有用。

---

## 評分：53/100

| 維度 | 分數 | 說明 |
|------|:---:|------|
| 新穎性 | 58 | Scout 是新的，但 Q2C 不比 SnapKV 好，混合精度被 KVTuner 搶走 |
| 實驗嚴謹度 | 38 | 兩個標題數字放大後都不顯著，量化實驗有 bug |
| 技術正確性 | 50 | 核心機制（位置傳輸）沒問題，但 claim 超過 evidence |
| 寫作品質 | 72 | 寫得清楚、格式正確，但缺 KVTuner/CacheGen 引用 |
| 影響力潛力 | 58 | Scout 的 28,800 倍壓縮有實用價值 |
| **加權總分** | **53** | 有根本問題，現狀不能投 |

53 分 = reject，但不是「東西沒價值」的 reject，而是「claim 和 evidence 對不上」的 reject。

---

## 怎麼救？一張表看懂

| 現在的 claim | 問題 | 修正方向 |
|-------------|------|---------|
| Q2C 比 SnapKV 好 29-47% | n=200 顯示沒差 | 改說「Q2C 與 SnapKV 效果相當，但 Q2C 計算更簡單」或「Q2C 在特定條件下有優勢」 |
| 7B scout 讓 14B 提升 10.2% | n=200 縮水到 4.7% 且不顯著 | 改說「scout 的選擇品質與 cloud 自己的選擇相當」，強調 28,800 倍壓縮而非品質提升 |
| 混合精度是我們的貢獻 | KVTuner (ICML 2025) 搶先了 | 降級成「支持性分析」，引用 KVTuner 並說明差異 |
| 兩篇獨立論文 | 各自太薄 | 合成一篇 JSAC，Scout 當主角，壓縮當配角 |

---

## 底線

**Scout 的概念本身是好的、是新的。** 沒有人做過「傳位置索引取代傳 KV 資料」，28,800 倍的壓縮比是真的。

問題出在包裝：論文把 n=50 的幸運數字當成標題，放大後站不住。

修法很明確：
1. 用 n=200 的數據重寫所有 claim
2. 把 Scout 的賣點從「品質更好」改成「品質相當但頻寬省 28,800 倍」
3. 合成一篇 JSAC，Scout 當主要貢獻
4. 引用 KVTuner 和 CacheGen，誠實定位

做完這些，這篇論文的競爭力會從 53 分跳到 70-75 分的區間（borderline accept），因為 Scout 的核心新穎性是真的。
